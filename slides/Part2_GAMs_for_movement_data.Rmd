---
title: "GAMs for movement data: families, interactions,  and dealing with autocorrelation"
author: "Eric Pedersen"
output:
  xaringan::moon_reader:
    css: ['default', 'https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css', 'slides.css']
    lib_dir: libs
    nature:
      titleSlideClass: ['inverse','middle','left',my-title-slide]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "macros.js"
      ratio: '16:9'
---

```{r setup, include=FALSE, cache=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(cache = TRUE, dev = 'svg', echo = TRUE, message = FALSE, warning = FALSE,
                      fig.height=6, fig.width = 1.777777*6)
library('here')
library('mgcv')
library('gratia')
library('gamair')
library('ggplot2')
library('purrr')
library('mvnfast')
library("tibble")
library('gganimate')
library('tidyr')
library("knitr")
library("viridis")
library('readr')
library('dplyr')
library('gganimate')
library('xaringan')
library('patchwork')
library('faraway')
library('sf')
library(extrafont)
## plot defaults
theme_set(theme_minimal(base_size = 16, base_family = 'Fira Sans'))
## constants
anim_width <- 1000
anim_height <- anim_width / 1.77777777
anim_dev <- 'png'
anim_res <- 200

xaringanExtra::embed_xaringan(
  url = "https://build-your-own-universe.netlify.app",
  ratio = "16:9"
)
xaringanExtra::use_scribble()
```

# So far:

- One-dimensional smooth models
- Models with multiple separate predictors
- Normally distributed response

These are good models, but there's lots more to see!


---

# New things



- distribution of the data
  - `family=` argument
  - special cases: counts, survival data, categorical
  
  
  
- Headaches and nightmares with high-frequency movement data:
  - Speeding up computation for big data
  - dealing with autocorrelation and spatial dependence
  
- adding dimensions to your smooths
  - Interactions between covariates
  - Individual-specific curves (HGAMs)
  
  


---

# Distributions

- `family=` argument in `gam()`
- see `?family.mgcv` for a list
- what you'd expect, as for `lm()` and `glm()`
- most useful cases:
  - `binomial` ( yes/no, $y \in \{0, 1\}$ )
  - `poisson` ( counts, $y \in \{0, 1, 2, \ldots\}$ )
  - `Gamma` ( positive, $y>0$ )

---

# Examples from movement data:

* Binomial: behavioural state, location (in-shore vs. offshore)
* Count: Number of observations at a station, number of encounters
* Continuous: depth or acceleration (Gamma), temperature (normal)

---

# Special count distributions

- Poisson is often not adequate for "real" counts
- Assuming $\text{Var}(y) = \mathbb{E}(y)$ is usually incorrect
 

```{r species-gala-plots, echo=FALSE, eval = TRUE,fig.height=4}


species_model <- gam(Species ~ log(Area), family=poisson, data=gala)

species_model_plot <- gala%>%
  ggplot(aes(x = Area, y= Species))+
  geom_point()+
  geom_line(aes(y=  fitted(species_model)))+
  scale_x_log10()+
  labs(title = "Galapagos Island SAR\nSpecies ~ log(Area)\nfamily=Poisson")


species_model_plot
```

---

# Special count distributions

- Poisson is often not adequate for "real" counts
- Assuming $\text{Var}(y) = \mathbb{E}(y)$ is usually incorrect
 
```{r species-gala-plots2, echo=FALSE, eval = TRUE, fig.height=4}
species_resid_plot <- gala %>%
  mutate(`Predicted mean` = fitted(species_model),
         `Predicted Var` = `Predicted mean`, 
         `Observed residuals` = Species-`Predicted mean`,
         `Simulated residuals` = rpois(n = n(), lambda = `Predicted mean`)- `Predicted mean`)%>%
  select(`Predicted mean`,`Predicted Var` ,`Observed residuals`, `Simulated residuals`)%>%
  gather(key = "outcome", value= "residual", -`Predicted mean`, - `Predicted Var`)%>%
  mutate(outcome =factor(outcome, levels = c("Simulated residuals","Observed residuals")))%>%
  ggplot(aes(x= `Predicted mean`, y= residual))+
  facet_grid(.~outcome)+
  geom_point()+
  geom_line(aes(y =sqrt(`Predicted Var`)))+
  geom_line(aes(y =-sqrt(`Predicted Var`)))
  
species_resid_plot

```
---

# Special "count-like" distributions


Other options?
 
- `quasipoisson` (count-ish, $y \geq 0$)
  - $\text{Var}(y) = \psi\times\mathbb{E}(y)$ 
  - awkward to check, no likelihood
  
--

- `nb`/`negbin` ( $y \geq 0$)
  - $\text{Var}(y) = \mathbb{E}(y) + \kappa\times\mathbb{E}(y)^2$ 
  - models overdispersed counts
  

--

- Models for categories:
  - `ocat`, `multinom`

---

# Negative binomial distribution

.pull-left[
```{r negbin, echo=FALSE, fig.height=5, fig.width=5}
y<-seq(1,12,by=1)
disps <- seq(0.01, 1, len=5)

fymat <- matrix(NA, length(y), length(disps))

i <- 1
for(disp in disps){
  fymat[,i] <- dnbinom(y, size=disp, mu=5)
  i <- i+1
}

plot(range(y), range(fymat), type="n", ylab="Density", xlab="Count", cex.lab=1.5,
     main="")

rr <- RColorBrewer::brewer.pal(8,"Dark2")

for(i in 1:ncol(fymat)){
  lines(y, fymat[,i], type="l", col=rr[i], lwd=2)
}

legend(x="topright", legend=disps, fill=rr, inset=0.05)

```
]
.pull-right[
- $\text{Var}\left(\text{count}\right) =$ $\mathbb{E}(\text{count}) + \kappa \mathbb{E}(\text{count})^2$
- Poisson is $\kappa=0$
- Estimate $\kappa$ for `nb`
- Set $\kappa$ for `negbin` 
]

---

## Families of special interest for movement ecologists:

- Cox Proportional Hazard: 

  - Model of "survival data": modelling relative probabilities of "survival" or "death" as function of covariates
  - Used for step selection: "death" = taken step, "survival" = alternative step
  


--

- `tw`/`Tweedie` ( $y \geq 0$)
  - Can handle both zero and positive values
  - Example usage: depth from bottom for benthopelagic species
  - $\text{Var}\left(\text{y}\right) = \phi\mathbb{E}(\text{y})^q$


---

## Families of special interest for movement ecologists:

- Location-scale models
  - `gaulss`,`gammals`, `gevless`
  - Used for modelling multiple parameters at once (e.g. mean and variance)
  - GEV: models "extreme" values:maxima or minima (make sure you know what it's doing!)
  


--

- Multivariate models:
  - `mvn`
  - e.g.: model speed and acceleration

---

# Other `family` stuff

- can specify a `link=` argument
  - (usually don't have to)
  - `?family` has options for each distribution
- for a fitted model `model$family`
  - details of what was used
  - `model$family$linkfun()` gives link function
  - `model$family$linkinv()` gives inverse link

---

# Let's pause the talk here to try this ourselves


---

class: inverse middle center big-subsection

## Dealing with big messy data issues in movement data


---

## Computation time:

Big data sets, many smooths complex smooths = a lot of memory + computation time


---

## Computation time:


Solutions: 

* Choose your smoothers carefully; 

* use `bam` instead of `gam`: can handle big data sets, but not huge speed-up

* use fewer basis functions

* `discrete = TRUE` in `bam`


* Think about subsampling your data 

---

## Statistical dependency:

Many observations occurring in close succession: close observations are similar to one another

---

## Problems arising from dependency: 

1. Your standard errors are bigger than they should be, and your smooths will be more wiggly than they should be

--

2. Covariates may vary slowly with time or space: makes it hard to distinguish if change in behaviour is due to the covariate or to a change in internal state


---

## How can we deal with dependency in GAMs?

Basic options:

**Subsample, or cross-validate**

--

* Upside: simple to understand + explain

--

* Downside: losing some data, have to decide on subsampling frequency


---

## How can we deal with dependency in GAMs?


**Add a smoother to model the dependency: e.g. `gam(y ~ s(speed) + s(time)`)**

--

* Upside: explicitly models dependency with smoothers, can do it all in one model

--

* Downside: need to assume model is correct, can be slow, can lead to strong fixed effects disappearing (see Hodges and Reich 2010: "Adding spatially-correlated errors can mess up the fixed effect you love") 

---

## How can we deal with dependency in GAMs?


**Adjust effective sample size to account for dependency: `gamma` parameter**

--

* Upsides: no need to model time

--

* Downside: does not solve the Hodges and Reich problem, have to figure out a model to calculate effective sample size 


---

# Let's pause the talk here to try this ourselves


---

class: inverse middle center big-subsection

## Interactions:<br/> spatial smoothers, tensor products, and modelling individual variation with HGAMs

---

# ü¶êüó∫

.pull-left[
- spatial variation!
- how do we model this??
- `s(long) + s(lat)` misses the interaction
]

.pull-right[
```{r biom-space-plot, fig.height=11, echo=FALSE}
coast <- read_sf(here("data/nl_coast.shp"))

ggplot(trawls_2010) +
  geom_point(aes(x=long, y=lat, size=shrimp)) +
  geom_sf(data=coast) +
  coord_sf()
```
]

---

# Adding dimensions

- Thin plate regression splines (default basis)
- `s(x, y)`
- Assumes `x` and `y` are measured in the same units
  - `x`, `y` projected coordinates üëç
  - `x` temperature, `y` depth üëé

---

# ü¶êüó∫

Starting with a 2D smooth, assuming data is Gaussian


.pull-left[
```{r shrimpmod}
spatial_shrimp <- gam(shrimp ~ s(x, y, k =100),
                data=trawls_2010,
                family = gaussian,
                method="REML")
```
]

.pull-right[
```{r plot-effect, fig.height=8}
plot(spatial_shrimp, asp=1)
```
]

---

# That plot is hard to understand!

.pull-left[
```{r plot-effect-bad, fig.height=10}
plot(spatial_shrimp, asp=1)

```
]

.pull-right[
```{r plot-effect-good, fig.height=10}
plot(spatial_shrimp, scheme=2, asp=1)

```
]

---

# Using gratia:
.left-column[

```{r plot-effect-gratia, fig.height=5, fig.show='hide'}
draw(spatial_shrimp)

```

]

.right-column[
```{r plot-effect-gratia2, fig.height=8, echo=FALSE}
draw(spatial_shrimp)

```
]

---

# `summary` output

```{r summary-spat, echo=FALSE}
summary(spatial_shrimp)

```


---

class: inverse middle center big-subsection

## Other multi-dimensional smooths

---

# `s(x,y)` doesn't always work

- Only works for `bs="tp"` or `bs="ts"`
- Covariates are isotropic
- What if we wanted to use lat/long?
- Or, more generally: interactions between covariates?

---

# Enter `te()`

.pull-left[
- We can built interactions using `te()`
- Construct 2D basis from 2 1D bases
- Biomass as a function of temperature and depth?
  - `te(temp_bottom, log10(depth))`
- üí≠ "marginal 1Ds, join them up"
]

.pull-right[
```{r tensor, echo=FALSE, results='hide', fig.width=8, fig.height=6, messages=FALSE, warning=FALSE}
b_shrimp_ll_ti <- gam(shrimp ~ ti(log10(depth), temp_bottom ) + ti(depth) + ti(temp_bottom)  ,
                data=trawls_2010,
                family=tw,
                method="REML")

layout(matrix(c(1,2,3,3), 2, 2), widths=c(1.5,1.5,1), height=c(1,1,2))
opar <- par(mar=c(4, 3, 1, 2) + 0.1)
plot(b_shrimp_ll_ti, select=3)
plot(b_shrimp_ll_ti, select=2)
par(mar=c(0, 0, 0, 0) + 0.1)
vis.gam(b_shrimp_ll_ti, view=c("temp_bottom","depth"), theta=-60, phi=30, color="bw")
par(opar)
```
]

---

# Using `te()`

Just like `s()`:


```{r te-ex}
shrimp_te <- gam(shrimp ~ te(log10(depth), temp_bottom),
                data=trawls_2010,
                family=tw,
                method="REML")
```

---

# `summary`

```{r te-ex-summary, echo=FALSE}
summary(shrimp_te)
```

---

# Things to fiddle with

- Setting `k` in two ways:
  - `k=5`: 5 for all covariates (total $5*5=25$)
  - `k=c(3,5)`: per basis, in order (total $3*5=15$)
- Setting `bs` in two  ways:
  - `bs="tp"`: tprs for all bases
  - `bs=c("tp", "tp")`: tprs per basis

---

# Pulling `te()` apart: `ti()`

- Can we look at the components of the `te()`
- `te(x, y) = ti(x, y) + ti(x) + ti(y)`

```{r tiex}
shrimp_ti <- gam(shrimp ~ ti(temp_bottom, depth) +
                          s(temp_bottom) + s(depth),
                data=trawls_2010,
                family=tw,
                method="REML")
```

---

# `summary`

```{r ti-ex-summary, echo=FALSE}
summary(shrimp_ti)
```

---

class: inverse middle center big-subsection

## Let's work through a couple examples


## Recap

---

# What did we learn?

- set response distribution
  - `family=` argument
  - see `?family`
- dealing with large and dependent data sets
- isotrophic smoothing for space
  - `s(x,y)` for projected coordinates
  - `te(lat, long)` for latitude and longitude (better to project?)
- interactions
  - `te(covar1, covar2, ...)`
  - `ti()` to decompose the effects


